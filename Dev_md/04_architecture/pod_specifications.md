# ğŸ“ POD ìƒì„¸ ëª…ì„¸ì„œ

## ëª©ì°¨
1. [POD ê³µí†µ ì¸í„°í˜ì´ìŠ¤](#pod-ê³µí†µ-ì¸í„°í˜ì´ìŠ¤)
2. [POD1: ë°ì´í„° ìˆ˜ì§‘](#pod1-ë°ì´í„°-ìˆ˜ì§‘)
3. [POD2: í¬ë¡­í•‘](#pod2-í¬ë¡­í•‘)
4. [POD3: íƒ€ì¼ë§](#pod3-íƒ€ì¼ë§)
5. [POD4: AI ë¶„ì„](#pod4-ai-ë¶„ì„)
6. [POD5: ë³‘í•©](#pod5-ë³‘í•©)
7. [POD6: GPKG ë°œí–‰](#pod6-gpkg-ë°œí–‰)

---

## POD ê³µí†µ ì¸í„°í˜ì´ìŠ¤

### ê¸°ë³¸ ì¸í„°í˜ì´ìŠ¤ ì •ì˜

```python
from abc import ABC, abstractmethod
from typing import Dict, Any, Optional
from pathlib import Path

class BasePOD(ABC):
    """ëª¨ë“  PODê°€ êµ¬í˜„í•´ì•¼ í•˜ëŠ” ê¸°ë³¸ ì¸í„°í˜ì´ìŠ¤"""
    
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.logger = self._setup_logger()
        self.output_dir = Path(config.get('output_dir'))
        self.output_dir.mkdir(parents=True, exist_ok=True)
    
    @abstractmethod
    def validate_input(self, **kwargs) -> bool:
        """ì…ë ¥ ë°ì´í„° ê²€ì¦"""
        pass
    
    @abstractmethod
    def process(self, **kwargs) -> Dict[str, Any]:
        """ë©”ì¸ ì²˜ë¦¬ ë¡œì§"""
        pass
    
    @abstractmethod
    def cleanup(self) -> None:
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        pass
    
    def run(self, **kwargs) -> Dict[str, Any]:
        """í‘œì¤€ ì‹¤í–‰ í”Œë¡œìš°"""
        try:
            self.validate_input(**kwargs)
            result = self.process(**kwargs)
            return result
        except Exception as e:
            self.logger.error(f"POD ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            raise
        finally:
            self.cleanup()
```

### ê³µí†µ ì„¤ì • ìŠ¤í‚¤ë§ˆ

```yaml
common:
  log_level: "INFO"
  output_format: "json"
  error_handling: "raise"  # raise, skip, retry
  max_retries: 3
  timeout: 3600  # seconds
```

---

## POD1: ë°ì´í„° ìˆ˜ì§‘

### ëª…ì„¸

| ì†ì„± | ë‚´ìš© |
|------|------|
| ì´ë¦„ | IngestionEngine |
| ëª©ì  | ë‹¤ì–‘í•œ í˜•ì‹ì˜ ì…ë ¥ ë°ì´í„°ë¥¼ í‘œì¤€í™”ëœ í˜•ì‹ìœ¼ë¡œ ë³€í™˜ |
| ì…ë ¥ | ECW/TIF ì´ë¯¸ì§€, Shapefile, Excel |
| ì¶œë ¥ | ë³€í™˜ëœ TIF, í†µí•© GeoDataFrame, ë©”íƒ€ë°ì´í„° |

### í´ë˜ìŠ¤ ì •ì˜

```python
class IngestionEngine(BasePOD):
    """
    POD1: ë°ì´í„° ìˆ˜ì§‘ ì—”ì§„
    """
    
    def __init__(self, config: Dict[str, Any]):
        super().__init__(config)
        self.target_crs = config.get('target_crs', 'EPSG:5186')
        self.ecw_to_tif = config.get('ecw_to_tif', True)
        
    def validate_input(self, 
                      image_path: Optional[str] = None,
                      shapefile_path: Optional[str] = None,
                      excel_path: Optional[str] = None) -> bool:
        """
        ì…ë ¥ íŒŒì¼ ê²€ì¦
        - íŒŒì¼ ì¡´ì¬ ì—¬ë¶€
        - í˜•ì‹ ê²€ì¦
        - í¬ê¸° ì œí•œ í™•ì¸
        """
        validations = []
        
        if image_path:
            validations.append(self._validate_image(image_path))
        if shapefile_path:
            validations.append(self._validate_shapefile(shapefile_path))
        if excel_path:
            validations.append(self._validate_excel(excel_path))
            
        return all(validations)
    
    def process(self,
               image_path: Optional[str] = None,
               shapefile_path: Optional[str] = None,
               excel_path: Optional[str] = None) -> Dict[str, Any]:
        """
        ë°ì´í„° ì²˜ë¦¬
        1. ECW â†’ TIF ë³€í™˜
        2. Shapefile ë¡œë“œ ë° ë³€í™˜
        3. Excel ë°ì´í„° ë§¤ì¹­
        4. ì¢Œí‘œê³„ í†µì¼
        """
        results = {
            'images': [],
            'parcels': None,
            'metadata': {}
        }
        
        # ì´ë¯¸ì§€ ì²˜ë¦¬
        if image_path:
            processed_image = self._process_image(image_path)
            results['images'].append(processed_image)
        
        # Shapefile ì²˜ë¦¬
        if shapefile_path:
            parcels = self._process_shapefile(shapefile_path)
            results['parcels'] = parcels
        
        # Excel ë°ì´í„° ë³‘í•©
        if excel_path and results['parcels'] is not None:
            results['parcels'] = self._merge_excel_data(
                results['parcels'], 
                excel_path
            )
        
        return results
```

### ë©”ì„œë“œ ìƒì„¸

```python
def _process_image(self, image_path: str) -> Dict[str, Any]:
    """ì´ë¯¸ì§€ ì²˜ë¦¬ ë¡œì§"""
    
    if image_path.endswith('.ecw') and self.ecw_to_tif:
        # ECW to TIF ë³€í™˜
        output_path = self._convert_ecw_to_tif(image_path)
    else:
        output_path = image_path
    
    # ë©”íƒ€ë°ì´í„° ì¶”ì¶œ
    with rasterio.open(output_path) as src:
        metadata = {
            'path': output_path,
            'crs': str(src.crs),
            'bounds': src.bounds,
            'shape': (src.height, src.width),
            'dtype': str(src.dtypes[0]),
            'transform': src.transform
        }
    
    return metadata

def _convert_ecw_to_tif(self, ecw_path: str) -> str:
    """ECW to TIF ë³€í™˜"""
    
    output_path = str(self.output_dir / Path(ecw_path).stem) + '.tif'
    
    # GDAL ì˜µì…˜ ì„¤ì •
    translate_options = gdal.TranslateOptions(
        format='GTiff',
        creationOptions=[
            'COMPRESS=LZW',
            'TILED=YES',
            'BLOCKXSIZE=512',
            'BLOCKYSIZE=512'
        ]
    )
    
    # ë³€í™˜ ì‹¤í–‰
    gdal.Translate(output_path, ecw_path, options=translate_options)
    
    return output_path
```

### ì„¤ì • ì˜ˆì‹œ

```yaml
ingestion:
  target_crs: "EPSG:5186"
  ecw_to_tif: true
  max_file_size: "10GB"
  validation:
    check_crs: true
    check_nodata: true
  output_format: "COG"  # Cloud Optimized GeoTIFF
```

---

## POD2: í¬ë¡­í•‘

### ëª…ì„¸

| ì†ì„± | ë‚´ìš© |
|------|------|
| ì´ë¦„ | CroppingEngine |
| ëª©ì  | ê´€ì‹¬ ì˜ì—­ ì¶”ì¶œ ë° ìµœì í™” |
| ì…ë ¥ | ì •ì‚¬ì˜ìƒ, ê²½ê³„ í´ë¦¬ê³¤ |
| ì¶œë ¥ | í¬ë¡­ëœ ì´ë¯¸ì§€ |

### í´ë˜ìŠ¤ ì •ì˜

```python
class CroppingEngine(BasePOD):
    """
    POD2: í¬ë¡­í•‘ ì—”ì§„
    """
    
    def __init__(self, config: Dict[str, Any]):
        super().__init__(config)
        self.use_convex_hull = config.get('use_convex_hull', True)
        self.buffer_size = config.get('buffer_size', 10)
        self.min_area = config.get('min_area', 100)
        
    def process(self, 
               image_data: Dict[str, Any],
               parcels: gpd.GeoDataFrame) -> Dict[str, Any]:
        """
        í¬ë¡­í•‘ ì²˜ë¦¬
        1. Convex Hull ìƒì„±
        2. ë²„í¼ ì ìš©
        3. ì´ë¯¸ì§€ í´ë¦¬í•‘
        """
        
        results = {
            'cropped_images': [],
            'cropped_regions': []
        }
        
        for idx, parcel in parcels.iterrows():
            # Convex Hull ì ìš©
            if self.use_convex_hull:
                geometry = parcel.geometry.convex_hull
            else:
                geometry = parcel.geometry
            
            # ë²„í¼ ì ìš©
            if self.buffer_size > 0:
                geometry = geometry.buffer(self.buffer_size)
            
            # ìµœì†Œ ë©´ì  í™•ì¸
            if geometry.area < self.min_area:
                continue
            
            # ì´ë¯¸ì§€ í¬ë¡­
            cropped = self._crop_image(image_data, geometry)
            
            results['cropped_images'].append(cropped)
            results['cropped_regions'].append({
                'id': idx,
                'geometry': geometry,
                'properties': parcel.to_dict()
            })
        
        return results
```

### í¬ë¡­í•‘ ì•Œê³ ë¦¬ì¦˜

```python
def _crop_image(self, 
               image_data: Dict[str, Any], 
               geometry: Polygon) -> Dict[str, Any]:
    """ì´ë¯¸ì§€ í¬ë¡­í•‘ êµ¬í˜„"""
    
    with rasterio.open(image_data['path']) as src:
        # ë§ˆìŠ¤í¬ ìƒì„±
        out_image, out_transform = mask(
            src, 
            [geometry], 
            crop=True,
            all_touched=True
        )
        
        # ë©”íƒ€ë°ì´í„° ì—…ë°ì´íŠ¸
        out_meta = src.meta.copy()
        out_meta.update({
            'driver': 'GTiff',
            'height': out_image.shape[1],
            'width': out_image.shape[2],
            'transform': out_transform,
            'compress': 'lzw'
        })
        
        # ì €ì¥
        output_path = self._generate_output_path()
        with rasterio.open(output_path, 'w', **out_meta) as dst:
            dst.write(out_image)
        
        return {
            'path': output_path,
            'transform': out_transform,
            'shape': out_image.shape,
            'bounds': geometry.bounds
        }
```

---

## POD3: íƒ€ì¼ë§

### ëª…ì„¸

| ì†ì„± | ë‚´ìš© |
|------|------|
| ì´ë¦„ | TilingEngine |
| ëª©ì  | ì´ë¯¸ì§€ë¥¼ ê· ì¼í•œ íƒ€ì¼ë¡œ ë¶„í•  |
| ì…ë ¥ | í¬ë¡­ëœ ì´ë¯¸ì§€ |
| ì¶œë ¥ | íƒ€ì¼ ì´ë¯¸ì§€, íƒ€ì¼ ì¸ë±ìŠ¤ |

### í´ë˜ìŠ¤ ì •ì˜

```python
class TilingEngine(BasePOD):
    """
    POD3: íƒ€ì¼ë§ ì—”ì§„
    """
    
    def __init__(self, config: Dict[str, Any]):
        super().__init__(config)
        self.tile_size = config.get('tile_size', 1024)
        self.overlap = config.get('overlap', 0.2)
        self.adaptive_tiling = config.get('adaptive_tiling', True)
        self.remove_empty = config.get('remove_empty', True)
        
    def process(self, cropped_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        íƒ€ì¼ë§ ì²˜ë¦¬
        1. íƒ€ì¼ ê·¸ë¦¬ë“œ ìƒì„±
        2. íƒ€ì¼ ì¶”ì¶œ
        3. ê³µê°„ ì¸ë±ìŠ¤ ìƒì„±
        """
        
        results = {
            'tiles': [],
            'tile_index': self._create_spatial_index()
        }
        
        for image_data in cropped_data['cropped_images']:
            tiles = self._generate_tiles(image_data)
            
            for tile in tiles:
                if self.remove_empty and self._is_empty_tile(tile):
                    continue
                    
                saved_tile = self._save_tile(tile)
                results['tiles'].append(saved_tile)
                
                # ê³µê°„ ì¸ë±ìŠ¤ ì—…ë°ì´íŠ¸
                self._update_spatial_index(
                    results['tile_index'], 
                    saved_tile
                )
        
        return results
```

### íƒ€ì¼ ìƒì„± ì•Œê³ ë¦¬ì¦˜

```python
def _generate_tiles(self, image_data: Dict[str, Any]) -> List[Dict]:
    """ì ì‘í˜• íƒ€ì¼ ìƒì„±"""
    
    with rasterio.open(image_data['path']) as src:
        # íƒ€ì¼ í¬ê¸° ê²°ì •
        if self.adaptive_tiling:
            tile_size = self._calculate_optimal_tile_size(
                src.width, 
                src.height
            )
        else:
            tile_size = self.tile_size
        
        # ìŠ¤íŠ¸ë¼ì´ë“œ ê³„ì‚°
        stride = int(tile_size * (1 - self.overlap))
        
        tiles = []
        for y in range(0, src.height, stride):
            for x in range(0, src.width, stride):
                # ìœˆë„ìš° ìƒì„±
                window = Window(
                    x, y,
                    min(tile_size, src.width - x),
                    min(tile_size, src.height - y)
                )
                
                # íƒ€ì¼ ë°ì´í„° ì½ê¸°
                tile_data = src.read(window=window)
                
                # íƒ€ì¼ ì •ë³´ ì €ì¥
                tiles.append({
                    'data': tile_data,
                    'window': window,
                    'transform': src.window_transform(window),
                    'bounds': src.window_bounds(window)
                })
        
        return tiles

def _calculate_optimal_tile_size(self, width: int, height: int) -> int:
    """ìµœì  íƒ€ì¼ í¬ê¸° ê³„ì‚°"""
    
    # ì´ë¯¸ì§€ í¬ê¸°ì— ë”°ë¥¸ ì ì‘í˜• íƒ€ì¼ë§
    min_dimension = min(width, height)
    
    if min_dimension < 512:
        return 256
    elif min_dimension < 2048:
        return 512
    elif min_dimension < 4096:
        return 1024
    else:
        return 2048
```

### ê³µê°„ ì¸ë±ìŠ¤ êµ¬í˜„

```python
def _create_spatial_index(self) -> index.Index:
    """R-tree ê³µê°„ ì¸ë±ìŠ¤ ìƒì„±"""
    
    p = index.Property()
    p.dimension = 2
    p.buffering_capacity = 10
    p.dat_extension = 'dat'
    p.idx_extension = 'idx'
    
    return index.Index(properties=p)

def _update_spatial_index(self, 
                         idx: index.Index, 
                         tile: Dict[str, Any]) -> None:
    """ê³µê°„ ì¸ë±ìŠ¤ ì—…ë°ì´íŠ¸"""
    
    # íƒ€ì¼ ê²½ê³„ ì¶”ê°€
    idx.insert(
        id=tile['id'],
        coordinates=tile['bounds']
    )
```

---

## POD4: AI ë¶„ì„

### ëª…ì„¸

| ì†ì„± | ë‚´ìš© |
|------|------|
| ì´ë¦„ | AnalysisEngine |
| ëª©ì  | YOLOv11 ê¸°ë°˜ ê°ì²´ íƒì§€ ë° ì„¸ê·¸ë©˜í…Œì´ì…˜ |
| ì…ë ¥ | íƒ€ì¼ ì´ë¯¸ì§€ |
| ì¶œë ¥ | íƒì§€ ê²°ê³¼ (JSON) |

### í´ë˜ìŠ¤ ì •ì˜

```python
class AnalysisEngine(BasePOD):
    """
    POD4: AI ë¶„ì„ ì—”ì§„
    """
    
    def __init__(self, config: Dict[str, Any]):
        super().__init__(config)
        self.model_name = config.get('model_name', 'yolov11x-seg')
        self.confidence_threshold = config.get('confidence_threshold', 0.25)
        self.device = config.get('device', 'cuda' if torch.cuda.is_available() else 'cpu')
        self.batch_size = config.get('batch_size', 8)
        self.classes = config.get('classes', self._default_classes())
        
        # ëª¨ë¸ ë¡œë“œ
        self.model = self._load_model()
        
    def _default_classes(self) -> Dict[int, str]:
        """ê¸°ë³¸ í´ë˜ìŠ¤ ì •ì˜"""
        return {
            0: "ìƒìœ¡ê¸°_ì‚¬ë£Œì‘ë¬¼",
            1: "ìƒì‚°ê¸°_ì‚¬ë£Œì‘ë¬¼",
            2: "ê³¤í¬_ì‚¬ì¼ë¦¬ì§€",
            3: "ë¹„ë‹í•˜ìš°ìŠ¤_ë‹¨ë™",
            4: "ë¹„ë‹í•˜ìš°ìŠ¤_ì—°ë™",
            5: "ê²½ì‘ì§€_ë“œë¡ ",
            6: "ê²½ì‘ì§€_ìœ„ì„±"
        }
    
    def process(self, tiles_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        AI ë¶„ì„ ì²˜ë¦¬
        1. ë°°ì¹˜ êµ¬ì„±
        2. ëª¨ë¸ ì¶”ë¡ 
        3. í›„ì²˜ë¦¬
        """
        
        results = {
            'detections': [],
            'statistics': {},
            'metadata': {}
        }
        
        # ë°°ì¹˜ ì²˜ë¦¬
        for batch in self._create_batches(tiles_data['tiles']):
            predictions = self._run_inference(batch)
            processed = self._postprocess(predictions, batch)
            results['detections'].extend(processed)
        
        # í†µê³„ ê³„ì‚°
        results['statistics'] = self._calculate_statistics(
            results['detections']
        )
        
        return results
```

### ì¶”ë¡  êµ¬í˜„

```python
def _run_inference(self, batch: List[Dict]) -> List:
    """ë°°ì¹˜ ì¶”ë¡  ì‹¤í–‰"""
    
    # ì´ë¯¸ì§€ ì¤€ë¹„
    images = [tile['data'] for tile in batch]
    
    # ì¶”ë¡ 
    with torch.no_grad():
        predictions = self.model(
            images,
            conf=self.confidence_threshold,
            device=self.device
        )
    
    return predictions

def _postprocess(self, 
                predictions: List, 
                batch: List[Dict]) -> List[Dict]:
    """ì¶”ë¡  ê²°ê³¼ í›„ì²˜ë¦¬"""
    
    processed = []
    
    for pred, tile in zip(predictions, batch):
        for detection in pred:
            processed.append({
                'tile_id': tile['id'],
                'class_id': int(detection.cls),
                'class_name': self.classes[int(detection.cls)],
                'confidence': float(detection.conf),
                'bbox': detection.xyxy.tolist(),
                'polygon': detection.masks.xy[0].tolist() if detection.masks else None,
                'transform': tile['transform']
            })
    
    return processed
```

### GPU ìµœì í™”

```python
def _optimize_batch_size(self) -> int:
    """GPU ë©”ëª¨ë¦¬ì— ë”°ë¥¸ ë°°ì¹˜ í¬ê¸° ìµœì í™”"""
    
    if self.device == 'cpu':
        return 1
    
    # GPU ë©”ëª¨ë¦¬ í™•ì¸
    gpu_memory = torch.cuda.get_device_properties(0).total_memory
    available_memory = gpu_memory - torch.cuda.memory_allocated()
    
    # ì´ë¯¸ì§€ í¬ê¸°ì™€ ëª¨ë¸ í¬ê¸° ê³ ë ¤
    image_size = self.tile_size * self.tile_size * 3 * 4  # RGB float32
    model_size = sum(p.numel() * p.element_size() for p in self.model.parameters())
    
    # ë³´ìˆ˜ì ì¸ ë°°ì¹˜ í¬ê¸° ê³„ì‚°
    optimal_batch = int(available_memory * 0.7 / (image_size + model_size))
    
    return min(max(1, optimal_batch), 32)
```

---

## POD5: ë³‘í•©

### ëª…ì„¸

| ì†ì„± | ë‚´ìš© |
|------|------|
| ì´ë¦„ | MergingEngine |
| ëª©ì  | íƒ€ì¼ë³„ íƒì§€ ê²°ê³¼ í†µí•© |
| ì…ë ¥ | ê°œë³„ íƒ€ì¼ íƒì§€ ê²°ê³¼ |
| ì¶œë ¥ | í†µí•©ëœ íƒì§€ ê²°ê³¼ |

### í´ë˜ìŠ¤ ì •ì˜

```python
class MergingEngine(BasePOD):
    """
    POD5: ë³‘í•© ì—”ì§„
    """
    
    def __init__(self, config: Dict[str, Any]):
        super().__init__(config)
        self.merge_strategy = config.get('merge_strategy', 'nms')
        self.iou_threshold = config.get('iou_threshold', 0.5)
        self.class_agnostic = config.get('class_agnostic', False)
        
    def process(self, detections_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        ë³‘í•© ì²˜ë¦¬
        1. ì¢Œí‘œ ë³€í™˜ (íƒ€ì¼ â†’ ì „ì—­)
        2. ì¤‘ë³µ ì œê±°
        3. ê²°ê³¼ í†µí•©
        """
        
        # ì „ì—­ ì¢Œí‘œë¡œ ë³€í™˜
        global_detections = self._convert_to_global_coords(
            detections_data['detections']
        )
        
        # ë³‘í•© ì „ëµ ì ìš©
        if self.merge_strategy == 'nms':
            merged = self._apply_nms(global_detections)
        elif self.merge_strategy == 'union':
            merged = self._apply_union(global_detections)
        elif self.merge_strategy == 'overlap':
            merged = self._apply_overlap(global_detections)
        else:
            raise ValueError(f"Unknown merge strategy: {self.merge_strategy}")
        
        return {
            'merged_detections': merged,
            'merge_statistics': self._calculate_merge_stats(
                len(global_detections), 
                len(merged)
            )
        }
```

### NMS êµ¬í˜„

```python
def _apply_nms(self, detections: List[Dict]) -> List[Dict]:
    """Non-Maximum Suppression ì ìš©"""
    
    if self.class_agnostic:
        return self._nms(detections)
    else:
        # í´ë˜ìŠ¤ë³„ NMS
        merged = []
        for class_id in set(d['class_id'] for d in detections):
            class_dets = [d for d in detections if d['class_id'] == class_id]
            merged.extend(self._nms(class_dets))
        return merged

def _nms(self, detections: List[Dict]) -> List[Dict]:
    """NMS ì•Œê³ ë¦¬ì¦˜ êµ¬í˜„"""
    
    if not detections:
        return []
    
    # ì‹ ë¢°ë„ ìˆœ ì •ë ¬
    sorted_dets = sorted(detections, key=lambda x: x['confidence'], reverse=True)
    
    keep = []
    while sorted_dets:
        # ê°€ì¥ ë†’ì€ ì‹ ë¢°ë„ ì„ íƒ
        best = sorted_dets.pop(0)
        keep.append(best)
        
        # IOU ê³„ì‚° ë° í•„í„°ë§
        sorted_dets = [
            d for d in sorted_dets 
            if self._calculate_iou(best['bbox'], d['bbox']) < self.iou_threshold
        ]
    
    return keep
```

### ì¢Œí‘œ ë³€í™˜

```python
def _convert_to_global_coords(self, detections: List[Dict]) -> List[Dict]:
    """íƒ€ì¼ ì¢Œí‘œë¥¼ ì „ì—­ ì¢Œí‘œë¡œ ë³€í™˜"""
    
    global_detections = []
    
    for det in detections:
        # ë³€í™˜ í–‰ë ¬ ì ìš©
        transform = det['transform']
        
        # ë°”ìš´ë”© ë°•ìŠ¤ ë³€í™˜
        global_bbox = self._transform_bbox(det['bbox'], transform)
        
        # í´ë¦¬ê³¤ ë³€í™˜ (ìˆëŠ” ê²½ìš°)
        global_polygon = None
        if det.get('polygon'):
            global_polygon = self._transform_polygon(det['polygon'], transform)
        
        global_det = det.copy()
        global_det['bbox'] = global_bbox
        global_det['polygon'] = global_polygon
        global_detections.append(global_det)
    
    return global_detections
```

---

## POD6: GPKG ë°œí–‰

### ëª…ì„¸

| ì†ì„± | ë‚´ìš© |
|------|------|
| ì´ë¦„ | GPKGExporter |
| ëª©ì  | GeoPackage í˜•ì‹ìœ¼ë¡œ ê²°ê³¼ ë°œí–‰ |
| ì…ë ¥ | ë³‘í•©ëœ íƒì§€ ê²°ê³¼ |
| ì¶œë ¥ | GPKG íŒŒì¼, HTML ë³´ê³ ì„œ |

### í´ë˜ìŠ¤ ì •ì˜

```python
class GPKGExporter(BasePOD):
    """
    POD6: GPKG ë°œí–‰ ì—”ì§„
    """
    
    def __init__(self, config: Dict[str, Any]):
        super().__init__(config)
        self.calculate_area = config.get('calculate_area', True)
        self.generate_report = config.get('generate_report', True)
        self.include_visualization = config.get('include_visualization', True)
        
    def process(self, 
               merged_data: Dict[str, Any],
               parcels_data: Optional[gpd.GeoDataFrame] = None) -> Dict[str, Any]:
        """
        GPKG ë°œí–‰ ì²˜ë¦¬
        1. ë ˆì´ì–´ êµ¬ì„±
        2. í†µê³„ ê³„ì‚°
        3. ë³´ê³ ì„œ ìƒì„±
        """
        
        # GeoDataFrame ìƒì„±
        detections_gdf = self._create_detections_gdf(
            merged_data['merged_detections']
        )
        
        # ë©´ì  ê³„ì‚°
        if self.calculate_area:
            detections_gdf['area_sqm'] = detections_gdf.geometry.area
            detections_gdf['area_ha'] = detections_gdf['area_sqm'] / 10000
        
        # GPKG íŒŒì¼ ìƒì„±
        gpkg_path = self._export_to_gpkg(detections_gdf, parcels_data)
        
        # ë³´ê³ ì„œ ìƒì„±
        report_path = None
        if self.generate_report:
            report_path = self._generate_html_report(
                detections_gdf, 
                parcels_data
            )
        
        # ì‹œê°í™”
        viz_path = None
        if self.include_visualization:
            viz_path = self._create_visualization(detections_gdf)
        
        return {
            'gpkg_path': gpkg_path,
            'report_path': report_path,
            'visualization_path': viz_path,
            'statistics': self._calculate_final_statistics(detections_gdf)
        }
```

### GPKG ìƒì„±

```python
def _export_to_gpkg(self, 
                   detections_gdf: gpd.GeoDataFrame,
                   parcels_gdf: Optional[gpd.GeoDataFrame]) -> str:
    """GeoPackage íŒŒì¼ ìƒì„±"""
    
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    gpkg_path = self.output_dir / f"nongview_results_{timestamp}.gpkg"
    
    # íƒì§€ ê²°ê³¼ ë ˆì´ì–´
    detections_gdf.to_file(
        gpkg_path,
        layer='detections',
        driver='GPKG'
    )
    
    # í•„ì§€ ë ˆì´ì–´ (ìˆëŠ” ê²½ìš°)
    if parcels_gdf is not None:
        parcels_gdf.to_file(
            gpkg_path,
            layer='parcels',
            driver='GPKG'
        )
        
        # í•„ì§€ë³„ í´ë¦½ëœ ê²°ê³¼
        clipped = self._clip_by_parcels(detections_gdf, parcels_gdf)
        clipped.to_file(
            gpkg_path,
            layer='clipped_detections',
            driver='GPKG'
        )
    
    # í†µê³„ í…Œì´ë¸”
    stats_df = self._create_statistics_table(detections_gdf)
    stats_df.to_file(
        gpkg_path,
        layer='statistics',
        driver='GPKG'
    )
    
    return str(gpkg_path)
```

### HTML ë³´ê³ ì„œ ìƒì„±

```python
def _generate_html_report(self,
                         detections_gdf: gpd.GeoDataFrame,
                         parcels_gdf: Optional[gpd.GeoDataFrame]) -> str:
    """HTML ë³´ê³ ì„œ ìƒì„±"""
    
    from jinja2 import Template
    
    template = Template('''
    <!DOCTYPE html>
    <html>
    <head>
        <title>Nong-View2 ë¶„ì„ ë³´ê³ ì„œ</title>
        <style>
            body { font-family: Arial, sans-serif; margin: 20px; }
            table { border-collapse: collapse; width: 100%; }
            th, td { border: 1px solid #ddd; padding: 8px; }
            th { background-color: #4CAF50; color: white; }
            .chart { width: 100%; height: 400px; }
        </style>
    </head>
    <body>
        <h1>Nong-View2 ë¶„ì„ ë³´ê³ ì„œ</h1>
        <h2>ì²˜ë¦¬ ì •ë³´</h2>
        <p>ì²˜ë¦¬ ì‹œê°„: {{ timestamp }}</p>
        <p>ì´ íƒì§€ ê°œìˆ˜: {{ total_detections }}</p>
        
        <h2>í´ë˜ìŠ¤ë³„ í†µê³„</h2>
        <table>
            <tr>
                <th>í´ë˜ìŠ¤</th>
                <th>ê°œìˆ˜</th>
                <th>ì´ ë©´ì  (ã¡)</th>
                <th>í‰ê·  ì‹ ë¢°ë„</th>
            </tr>
            {% for row in class_stats %}
            <tr>
                <td>{{ row.class_name }}</td>
                <td>{{ row.count }}</td>
                <td>{{ "%.2f"|format(row.total_area) }}</td>
                <td>{{ "%.3f"|format(row.avg_confidence) }}</td>
            </tr>
            {% endfor %}
        </table>
        
        {% if parcel_stats %}
        <h2>í•„ì§€ë³„ í†µê³„</h2>
        <table>
            <tr>
                <th>PNU</th>
                <th>íƒì§€ ê°œìˆ˜</th>
                <th>ì£¼ìš” í´ë˜ìŠ¤</th>
            </tr>
            {% for row in parcel_stats %}
            <tr>
                <td>{{ row.pnu }}</td>
                <td>{{ row.detection_count }}</td>
                <td>{{ row.main_class }}</td>
            </tr>
            {% endfor %}
        </table>
        {% endif %}
        
        <h2>ì²˜ë¦¬ ë©”íƒ€ë°ì´í„°</h2>
        <pre>{{ metadata | tojson(indent=2) }}</pre>
    </body>
    </html>
    ''')
    
    # í†µê³„ ê³„ì‚°
    class_stats = detections_gdf.groupby('class_name').agg({
        'class_name': 'count',
        'area_sqm': 'sum',
        'confidence': 'mean'
    }).rename(columns={
        'class_name': 'count',
        'area_sqm': 'total_area',
        'confidence': 'avg_confidence'
    }).reset_index()
    
    # HTML ìƒì„±
    html_content = template.render(
        timestamp=datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
        total_detections=len(detections_gdf),
        class_stats=class_stats.to_dict('records'),
        parcel_stats=self._calculate_parcel_stats(detections_gdf, parcels_gdf),
        metadata=self.config
    )
    
    # íŒŒì¼ ì €ì¥
    report_path = self.output_dir / 'analysis_report.html'
    report_path.write_text(html_content, encoding='utf-8')
    
    return str(report_path)
```

---

## ì„±ëŠ¥ ì§€í‘œ

### ê° PODë³„ ì²˜ë¦¬ ì‹œê°„

| POD | ì²˜ë¦¬ëŸ‰ | í‰ê·  ì‹œê°„ | ë©”ëª¨ë¦¬ ì‚¬ìš© |
|-----|--------|-----------|------------|
| POD1 | 1GB ì´ë¯¸ì§€ | 30s | 2GB |
| POD2 | 100 í´ë¦¬ê³¤ | 15s | 1GB |
| POD3 | 1000 íƒ€ì¼ | 20s | 500MB |
| POD4 | 100 íƒ€ì¼/ë¶„ | - | 4GB (GPU) |
| POD5 | 10000 ê°ì²´ | 5s | 1GB |
| POD6 | 5000 ê°ì²´ | 20s | 500MB |

---

## ì—ëŸ¬ ì²˜ë¦¬

### ê³µí†µ ì—ëŸ¬ ì½”ë“œ

```python
class PODError(Exception):
    """POD ì—ëŸ¬ ê¸°ë³¸ í´ë˜ìŠ¤"""
    
    ERROR_CODES = {
        1001: "ì…ë ¥ íŒŒì¼ ì—†ìŒ",
        1002: "ì˜ëª»ëœ íŒŒì¼ í˜•ì‹",
        1003: "ì¢Œí‘œê³„ ë¶ˆì¼ì¹˜",
        2001: "ë©”ëª¨ë¦¬ ë¶€ì¡±",
        2002: "GPU ì‚¬ìš© ë¶ˆê°€",
        3001: "ì²˜ë¦¬ íƒ€ì„ì•„ì›ƒ",
        3002: "ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨"
    }
```

### ì—ëŸ¬ ì²˜ë¦¬ ì „ëµ

```python
def handle_error(self, error: Exception) -> None:
    """ì—ëŸ¬ ì²˜ë¦¬ ì „ëµ"""
    
    if self.config['error_handling'] == 'raise':
        raise error
    elif self.config['error_handling'] == 'skip':
        self.logger.warning(f"ì—ëŸ¬ ë°œìƒ, ê±´ë„ˆë›°ê¸°: {error}")
        return None
    elif self.config['error_handling'] == 'retry':
        for attempt in range(self.config['max_retries']):
            try:
                # ì¬ì‹œë„ ë¡œì§
                pass
            except Exception as e:
                if attempt == self.config['max_retries'] - 1:
                    raise
                time.sleep(2 ** attempt)  # ì§€ìˆ˜ ë°±ì˜¤í”„
```

---

ë¬¸ì„œ ë²„ì „: 1.0.0
ìµœì¢… ìˆ˜ì •: 2024-11-06